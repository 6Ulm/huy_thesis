
\chapter{Fused Unbalanced Gromov-Wasserstein} \label{chap:fugw}

% \addcontentsline{tot}{chapter}{section}
\renewcommand{\contentsname}{Contents}
\localtableofcontents*
\chaptermark{\textbf{Fused Unbalanced Gromov-Wasserstein}}

\hfill \break

\raggedbottom

This chapter presents the results from \citep{Thual22} and addresses the applications of
unbalanced extension of fused Gromov-Wasserstein in human brains alignments.
Individual brains vary in both anatomy and functional organization, even within a given species.
Inter-individual variability is a major impediment when trying to draw generalizable conclusions
from neuroimaging data collected on groups of subjects.
Current co-registration procedures rely on limited data, and thus lead to very coarse
inter-subject alignments.
In this work, we present a novel method for inter-subject alignment based on Optimal Transport,
denoted as Fused Unbalanced Gromov-Wasserstein (FUGW).
The method aligns cortical surfaces based on the similarity of their functional signatures in
response to a variety of stimulation settings, while penalizing large deformations of
individual topographic organization.
We demonstrate that FUGW is well-suited for whole-brain landmark-free alignment.
The unbalanced feature allows to deal with the fact that functional areas
vary in size across subjects. Our results show that FUGW alignment significantly
increases between-subject correlation of activity for independent functional data,
and leads to more precise mapping at the group level.

\raggedbottom

%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}

The availability of millimeter or sub-millimeter anatomical or functional brain images has opened
new horizons to
neuroscience, namely that of mapping cognition in the human brain and detecting markers of diseases.
%
Yet this endeavour has stumbled on the roadblock of inter-individual
variability: while the overall organization of the human brain is largely invariant,
two different brains (even from monozygotic twins \citep{pizzigali2020})
may differ at the scale of centimeters in shape, folding pattern, and functional responses.
%
% While variability is a hindrance to brain mapping,
The problem is further complicated by the fact that functional images
are noisy, due to imaging limitations and behavioral
differences across individuals that cannot be easily overcome.
%
The status quo of the field is thus to rely on anatomy-based inter-individual alignment
that approximately matches the outline of the brain \citep{ants}
as well as its large-scale cortical folding patterns \citep{fs_reconall,fischl_freesurfer_2012}.
%
Existing algorithms thus coarsely match anatomical features with diffeomorphic transformations,
by warping individual data to a simplified template brain.
Such methods lose much of the original individual detail and blur the functional information
that can be measured in brain regions (see \Cref{fig:intro}).

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{./Chapitre4/figures/intro_variation.pdf}
    \caption[High variability in human anatomies and functional MRI responses across subjects]{
        \textbf{High variability in human anatomies and functional MRI responses across subjects}
        In this experiment contrasting areas of the brain
        which respond to mathematical tasks against other that
        don't, we observe great variability in locations and strength of brain activations across subjects (row 1).
        The classical approach consists in wrapping this data
        to a common surface template (row 2), where they can be averaged, often resulting in
        loss of individual details and detection power.
        These images were generated using Nilearn software \citep{abraham_machine_2014}.
    }
    \label{fig:intro}
\end{figure}
In order to improve upon the current situation, a number of challenges have to be addressed:
%
\textit{(i)} There exists no template brain with functional information,
which by construction renders any cortical matching method blind to function.
This is unfortunate, since functional information is arguably the most accessible marker
to identify cortical regions and their boundaries \citep{Glasser2016-ha}.
%
\textit{(ii)} When comparing two brains -- coming from individuals or from a template --
it is unclear what regularity should be imposed on the matching \citep{vanessen2012}.
While it is traditional in medical imaging to impose diffeomorphicity \citep{ants},
such a constrain does not match the frequent observation that brain regions vary
across individuals in their fine-grained functional organization \citep{Glasser2016-ha,schneider2019}.
% \bt{find other ref}
%
\textit{(iii)} Beyond the problem of aligning human brains, it is an even greater challenge
to systematically compare functional brain organization in two different species,
such as humans and macaques \citep{neubert_comparison_2014,mars_whole_2018,xu_cross-species_2020,eichert_cross-species_2020,}.
Such inter-species comparisons introduce a more extreme form of variability in the correspondence model.

\paragraph{Related work}
%
Several attempts have been made to constrain the brain alignment process by using
functional information. The first one consists in introducing functional maps into
the diffeomorphic framework and search for a smooth transformation that matches
functional information \citep{sabuncu_function-based_2010,yeo_spherical_2010,robinson_msm_2014},
the most popular framework being arguably Multimodal Surface Matching (MSM)
\citep{robinson_msm_2014,Glasser2016-ha}.

A second family of less constrained functional alignment approaches have been proposed,
based on heuristics, by matching information in small, possibly overlapping,
cortical patches \citep{haxby_common_2011,Tavor2016-rl,bazeille_empirical_2021}.
%
This popular framework has been called \emph{hyperalignment}
\citep{haxby_common_2011,guntupalli_model_2016}, or \emph{shared response models} \citep{Chen2015}.
%
Yet these approaches lack a principled framework and cannot be considered to solve
the matching problem at scale. Neither do they allow to estimate %
a group-level template properly \citep{alwasity2020}.

An alternative functional alignment framework has followed another path \citep{gramfort2015},
considering functional signal as a three-dimensional distribution, and minimizing the transport cost.
However, this framework imposes unnatural constraints of non-negativity of the signal and % approximate normalization.
only works for one-dimensional contrasts, so that it cannot be used to learn
multi-dimensional anatomo-functional structures.
%
An important limitation of the latter two families of methods is that they operate on
a fixed spatial context (mesh or voxel grid), and thus cannot be used on heterogeneous meshes
such as between two individual human anatomies or, worse, between a monkey brain
and a human brain.

\paragraph{Contributions}

Following \citep{bazeille_local_2019}, we use the Wasserstein distance between source and
target functional signals -- consisting of contrast maps acquired with fMRI --
to compute brain alignments. We contribute two notable extensions of this framework:
\textit{(i)} a Gromov-Wasserstein (GW) term to preserve global anatomical structure --
this term introduces an anatomical penalization against improbably distant anatomical matches,
yet without imposing diffeomorphic regularity -- as well as
\textit{(ii)} an unbalanced correspondence that allows mappings from one brain to another
to be incomplete, for instance because some functional areas are larger in some individuals
than in others, or may simply be absent. We show that this approach successfully addresses
the challenging case of different cortical meshes, and that derived brain activity templates
are sharper than those obtained with standard anatomical alignment approaches.

\section{Methods}
\label{sec:methods}

Optimal Transport yields a natural framework to address the alignment problem,
as it seeks to derive a plan -- a \textit{coupling} -- that can be seen as a soft assignment matrix
between cortical areas of a source and target individual.
As discussed previously, there is a need for a functional alignment method that respects
the rich geometric structure of the anatomical features, hence the Wasserstein distance alone
is not sufficient. By construction, the GW distance \citep{Memoli11,Memoli07}
can help preserve the global geometry underlying the signal.
The more recent fused GW distance \citep{Vayer19b} goes one step further by
making it possible to integrate functional data simultaneously with anatomical information.

\subsection{Fused Unbalanced Gromov-Wasserstein}

We leverage \citep{Vayer19b,Sejourne20} to present a new objective function which interpolates
between a loss preserving the global geometry of the underlying mesh structure and
a loss aligning source and target features, while simultaneously allowing not to transport
some parts of the source and target distributions. We provide an open-source solver
that minimizes this loss
\footnote{\href{https://github.com/alexisthual/fugw}{https://github.com/alexisthual/fugw}
provides a PyTorch \citep{NEURIPS2019_9015} solver with a scikit-learn \citep{scikit-learn}
compatible API}.

\paragraph{Formulation}
We denote $F^s \in \bbR^{n \times c}$ the matrix of features per vertex for the source subject.
In the proposed application, they correspond to $c$ functional activation maps,
sampled on a mesh with $n$ vertices representing the source subject's cortical surface.
Let $D^s \in \bbR^{n \times n}_+$ be the matrix of pairwise geodesic distances
\footnote{We compute geodesic distances using
\href{https://github.com/the-virtual-brain/tvb-gdist}{https://github.com/the-virtual-brain/tvb-gdist}}
between vertices of the source mesh.
Moreover, we assign the distribution $w^s \in \bbR^{n}_+$ on the source vertices.
Comparably, we define $F^t \in \bbR^{p \times c}$, $D^t \in \bbR^{p \times p}_+$ and
$w^t \in \bbR^{p}_+$ for the target subject, whose individual anatomy is represented
by a mesh comprising $p$ vertices.
Eventually, $w^s$ and $w^t$ set the transportable mass per vertex, which,
without prior knowledge, we choose to be uniform for the source and target vertices respectively:
$w^s \triangleq (\frac{1}{n}, ..., \frac{1}{n})$,
$w^t \triangleq (\frac{1}{p}, ..., \frac{1}{p})$.

Given a tuple of hyper-parameters $\theta \triangleq (\rho, \alpha, \varepsilon)$,
where $\rho, \varepsilon \in \bbR_+$ and $\alpha \in [0,1]$,
for any coupling $P \in \bbR^{n \times p}_{\geq 0}$,
we define the fused unbalanced Gromov-Wasserstein loss as
\begin{equation}
    \label{eq:fugw_obj_func}
    \begin{split}
        L_{\theta}(P) &=
        (1 - \alpha) \underbrace{\sum_{i,j} || F^s_i - F^t_j||_2^2 P_{ij}}_{\text{Wasserstein loss } L_{\text{W}}(P)}
        + \alpha \underbrace{\sum_{i,j,k,l} | D^s_{ik} - D^t_{jl}|^2 P_{ij} P_{kl}}_{\text{Gromov-Wasserstein loss } L_{\gw}(P)} \\
        &+ \rho \underbrace{\left[ \kl(P_{\# 1} \otimes P_{\# 1} \vert w^s \otimes w^s)
        + \kl(P_{\# 2} \otimes P_{\# 2} \vert w^t \otimes w^t) \right]}_{\text{Marginal constraints } L_{\text{U}}(P)}
        + \varepsilon \underbrace{E(P)}_{\text{Entropy}}
    \end{split}
\end{equation}
where $L_{\text{W}}(P)$ matches vertices with similar features,
$L_{\gw}(P)$ penalizes changes in geometry
and $L_{\text{U}}(P)$ fosters matching all parts of the source and target distributions.
Throughout this paper, we refer to relaxing the hard marginal constraints of the underlying
OT problem into soft ones as \textit{unbalancing}.
Here, $P_{\# 1} \triangleq (\sum_j P_{i,j})_{0 \leq i < n}$ denotes
the first marginal distribution of $P$,
and $P_{\# 2} \triangleq (\sum_i P_{i,j})_{0 \leq j < p}$
the second marginal distribution of $P$. The notation $\otimes$ represents
the Kronecker product between two vectors or two matrices.
$\kl(\cdot|\cdot)$ denotes the Kullback Leibler divergence,
which is a typical choice to measure the discrepancy between two measures
in the context of unbalanced optimal transport \citep{Liero18}.
The last term $E(P) \triangleq \kl \big(P \otimes P | (w^s \otimes w^t) \otimes (w^s \otimes w^t)\big)$
is mainly introduced for computational purposes, as it helps accelerate
the approximation scheme of the optimisation problem. Typically,
it is used in combination with a small value of $\varepsilon$,
so that the impact of other terms is not diluted. On the other hand,
the parameters $\alpha$ and $\rho$ offer control over two other aspects of the problem:
while $\alpha$ realizes a trade-off between the impact of different features and
different geometries in the resulting alignment, $\rho$ controls the amount of
mass transported by penalizing configurations such that the marginal distributions
of the transportation plan $P$ are far from the prior weights $w^s$ and $w^t$.
This potentially helps adapting the size of areas where either the signal or the geometry
differs too much between source and target.

Eventually, we define $\cX^s \triangleq (F^s, D^s, w^s)$ and $\cX^t \triangleq (F^t, D^t, w^t)$,
and seek to derive an optimal coupling $P \in \bbR^{n \times p}_{\geq 0}$ minimizing
\begin{equation}
    \label{eq:fugw}
    \begin{split}
        \fugw(\cX^s, \cX^t)
        &\triangleq \inf_{P \in \bbR^{n \times p}_{\geq 0}} L_{\theta}(P).
    \end{split}
\end{equation}
This can be seen as a natural combination of the fused GW \citep{Vayer19b}
and the unbalanced GW \citep{Sejourne20} distances. To the best of our knowledge,
it has never been considered in the literature.

\paragraph{Toy example illustrating the unbalancing property}

As exemplified in \Cref{fig:intro}, brain responses elicited by the same stimulus
vary greatly between individuals.
\Cref{fig:toy_example} illustrates a similar yet simplified version of this problem,
where the goal is to align two different signals  supported on the same spherical meshes.
In this example, for each of the $n=p=3200$ vertices, the feature is simply a scalar.
On the source mesh, the signal is constituted of two von Mises density functions that differ
by their concentration (large and small), while on the target mesh, only the large one is present,
but at a different location.
We use the optimal coupling matrix $P$ obtained from Equation \eqref{eq:fugw} to transport
the source signal on the target mesh.
As shown in \Cref{fig:toy_example}.B, the parameter $\rho$ allows to control
the mass transferred from source to target.
When $\rho=100$, we approach the solution of the fused GW problem. Consequently,
we observe the second mode on the target when transporting the source signal.
When the mass control is weaker ($\rho=1$), the smaller blob is partly removed because
it has no counterpart in the target configuration, making the transport ill-posed.
\iffalse This corresponds to a mass destruction, as depicted on the right of the Figure,
whereas the larger blob in the target distribution is also a place of mass creation. \fi

\begin{figure}[t]
    \centering
    \includegraphics[width=1\columnwidth]{./Chapitre4/figures/toy_example.pdf}
    \caption[Unbalancing helps accounting for idiosyncrasies of the source and target signals]{
        \textbf{Unbalancing helps accounting for idiosyncrasies of the source and target signals}
        When trying to align the source and target signals (Panel A),
        the classical balanced setup (Panel B, top row) transports all parts of
        the source signal even if they have no counterpart in the target signal.
        In the unbalanced setup (Panel B, bottom row), less source-only signal is transported:
        in particular, less mass is transported from the source's small blob onto the target
        (Panel B, middle column).
    }
    \label{fig:toy_example}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Optimization}

Estimating the unbalanced Gromov Wasserstein loss is numerically sensitive to initialization,
due to the non-convexity of the problem.
Therefore, FUGW is also \textit{a priori} non-convex, and comparably difficult to estimate.
Consequently, following \citep{Sejourne20}, we instead compute a lower bound which
is formulated as a bi-convex problem that relies on the joint estimation of two couplings.
\begin{align}
    \label{eq:lbfugw}
    \quad \fugw(\cX^s, \cX^t) = \inf_{\substack{P, Q \in \bbR^{n \times p}_{\geq 0} \\ P = Q}}
    L_{\theta}(P, Q) \geq \inf_{\substack{P, Q \in \bbR^{n \times p}_{\geq 0} \\ m(P) = m(Q)}}
    L_{\theta}(P, Q) \triangleq \text{LB-FUGW} (\cX^s, \cX^t),
\end{align}
where $m(P) = \sum_{i,j} P_{i,j}$ denotes the mass of $P$ and
\begin{equation}
    \label{eq:fugw_loss_two_couplings}
    \begin{split}
        L_{\theta}(P, Q) \triangleq
        (1 - \alpha) \enspace L_{\text{W}}(P, Q) + \alpha \enspace L_{\gw}(P, Q)
        + \rho \enspace L_{\text{U}}(P, Q) + \varepsilon \enspace E(P, Q),
    \end{split}
\end{equation}
where
\begin{itemize}
    \item[$\bullet$] $C \triangleq \Big( ||F^s_{i} - F^t_j||^2_2\Big)_{i,j} \in \bbR^2_+$ \hfill (feature cost matrix)

    \item[$\bullet$] $G \triangleq \Big( |D^s_{i,j} - D^t_{k,l}| \Big)_{i,j,k,l} \in \bbR^4_+$ \hfill (geometry cost tensor)

    \item[$\bullet$] $L_{\text{W}}(P, Q) \triangleq \langle C, \frac{P + Q}{2} \rangle = \frac{1}{2} ( \sum_{i,j} C_{i,j}P_{i,j} + \sum_{i,j} C_{i,j}Q_{i,j})$ \hfill (Wasserstein)

    \item[$\bullet$] $L_{\gw}(P, Q) \triangleq \langle G , P \otimes Q \rangle = \sum_{i,j,k,l}G_{i,j,k,l}P_{i,j}Q_{k,l}$ \hfill (Gromov-Wasserstein)

    \item[$\bullet$] $L_{\text{U}}(P, Q) \triangleq \enspace \kl \Big(P_{\# 1} \otimes Q_{\# 1} \vert w^s \otimes w^s \Big) + \enspace \kl \Big(P_{\# 2} \otimes Q_{\# 2} \vert w^t \otimes w^t \Big)$ \hfill (unbalancing)

    \item[$\bullet$] $E(P, Q) \triangleq \kl \Big(P \otimes Q | (w^s \otimes w^t) \otimes (w^s \otimes w^t) \Big)$ \hfill (entropy)
\end{itemize}
In particular, we have $L_{\theta}(P, P) = L_{\theta}(P)$,
which is the objective function of FUGW introduced in Equation \eqref{eq:fugw_obj_func}.
It is difficult to study when equality holds between FUGW and its lower bound.
Here, we attempt to understand the potential gap between them.
First, let us introduce the following problem
\begin{equation}
  \widetilde{\fugw}(\cX^s, \cX^t) = \inf_{(P, Q) \in \cE} L_{\theta}(P, Q),
\end{equation}
where $\cE = \{P, Q \in \bbR^{n \times p}_{\geq 0}: P_{\#1} = Q_{\#1}, P_{\#2} = Q_{\#2} \}$ is
the set of pairs of transportation plans whose corresponding marginal distributions are equal.
Clearly, we have
\begin{equation}
    \text{LB-FUGW} (\cX^s, \cX^t) \leq \widetilde{\fugw}(\cX^s, \cX^t)
    \leq \fugw(\cX^s, \cX^t).
\end{equation}
This inequality indicates that the difference between FUGW and LB-FUGW might be potentially large.
However, this gap can be tightened under the conditions in \Cref{prop:coot_gw_equiv}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{corollary} \label{coro:ugw_ucoot}
    If the distances $D^s$ and $D^t$ are of the forms: $D^s_{ij} = f_i + f_j + A_{ij}$ and
    $D^t_{kl} = g_k + g_l + B_{kl}$, where $f, g$ are vectors in $\bbR^n, \bbR^p$, respectively,
    and the matrices $A, B$ are both conditionally negative semi-definite, then we have
    $\fugw (\cX^s, \cX^t) = \widetilde{\fugw}(\cX^s, \cX^t)$.
    % Furthermore, if the definiteness holds, then the optimal solution satisfies $P^* = Q^*$,
    % meaning that $\text{LB-FUGW} (\cX^s, \cX^t) = \fugw(\cX^s, \cX^t)$.
\end{corollary}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% In our experiments, while the geodesic distances do not necessarily meet these conditions,
In our experiments, while the geodesic distances do not necessarily meet these conditions,
we still observe that the two couplings of LB-FUGW are numerically equal.
So it is enough to choose, for example, the first one, as alignment between source and target signals.

The lower bound of FUGW \eqref{eq:lbfugw} involves solving a minimization problem with respect to two independent couplings.
Using a Block-Coordinate Descent (BCD) scheme, we fix a coupling and minimize
with respect to the other. This allows us to always be dealing with linear problems
instead of a quadratic one. Eventually, each BCD iteration consists in alternatively solving
two entropic unbalanced OT problems, whose solutions can be approximated using
the Sinkhorn algorithm \citep{Sejourne19}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{FUGW Barycenters}
Barycenters represent common patterns across samples.
Their role is instrumental in identifying a unique target for aligning a given group of individuals.
As seen in \Cref{fig:intro}, the vertex-wise group average does not usually provide
well-contrasted maps.
Inspired by the success of the GW distance when estimating the barycenter of structured objects
\citep{Peyre16,Vayer19b}, we use FUGW to find the barycenter
$(F_B, D_B) \in \bbR^{k \times c} \times \bbR^{k \times k}$
of all subjects $s \in \cS$, as well as the corresponding couplings $P^{s,B}$ from each subject
to the barycenter. More precisely, we solve
\begin{equation}
    \label{eq:barycenter}
    \cX^B = (F_B, D_B, w^B) \in \argmin_{\cX}  \sum_{s \in \cS} \fugw(\cX^s, \cX),
\end{equation}
where we set the weights $w_B$ to be the uniform distribution.
By construction, the resulting barycenter benefits from the advantages of FUGW,
i.e. equilibrium between geometry-preserving and feature-matching properties,
while not forcing hard marginal constraints. The FUGW barycenter is estimated
using a Block-Coordinate Descent (BCD) algorithm that consists in alternatively
\textit{(i)} minimizing the OT plans $P^{s,B}$ for each FUGW computation
in \eqref{eq:barycenter} with fixed $\cX^B$ and \textit{(ii)}
updating the barycenter $\cX^B$ through a closed form with fixed $P^{s,B}$.
See \Cref{alg:fugw_barycenter} for more details.
The first step simply uses the previously introduced solver.
The second one takes advantage of the fact that the objective function introduced
in \eqref{eq:lbfugw} is differentiable in $F^B$ and $D^B$, and the two couplings of
LB-FUGW are numerically equal. This yields a closed form for $F^B$ and $D^B$,
as a function of $P^{s,B}$ and $\cX^s$. We note that, during the barycenter estimation,
the weight $w^B$ is always fixed as uniform distribution.

\begin{algorithm}[t]
    \caption{LB-FUGW barycenter for Problem \eqref{eq:barycenter}}
    \label{alg:fugw_barycenter}
    \begin{algorithmic}[1]
        \STATE \textbf{Input:} $(\cX^s)_{s \in \cS}, \rho, \alpha, \varepsilon$.
        \STATE \textbf{Output:} Individual couplings $(P^{s, B})_{s \in \cS}$, barycenter $\cX^B$.
        \STATE Initialize: $F^B = \mathbb I_k$; $D^B = 0_k$.
        \WHILE{$\cX^B = (F^B, D^B, w^B)$ has not converged}
            \STATE Draw $\widetilde{S}$ subset of $S$.
            \FOR{$s \in \widetilde{S}$}
                \STATE Align: $P^{s, B} \gets \text{LB-FUGW}(\cX^s, \cX^B, \rho, \alpha, \varepsilon)$.
                \COMMENT{Fixed $\cX^B$}
            \ENDFOR
            \STATE Update $F^B$, $D^B$:
            \COMMENT{Fixed $P^{s, B}$}
            \begin{equation*}
                F^B = \frac{1}{| \widetilde{S} |} \sum_{s \in \widetilde{S}}
                \text{diag} \left( \frac{1}{P^{s, B}_{\# 2}} \right)
                (P^{s, B})^\top F^s \; \text{ and } \;
                D_B = \frac{1}{| \widetilde{S} |} \sum_{s \in \widetilde{S}}
                \frac{(P^{s, B})^\top D^s P^{s, B}}{P^{s, B}_{\# 2} (P^{s, B}_{\# 2})^\top}.
            \end{equation*}
        \ENDWHILE
    \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Ã¹
\section{Numerical experiments}

We design three experiments to assess the performance of FUGW.
In Experiments 1 and 2, we are interested in assessing if aligning pairs of individuals with
FUGW increases correlation between subjects compared to a baseline correlation.
We also compare the ensuing gains with those obtained when using the
competing method MSM \citep{robinson_msm_2014,robinson_multimodal_2018} to align subjects.
In Experiment 3, we derive a barycenter of individuals and assess its ability to capture fine-grained
details compared to classical methods.

\subsection{Experimental settings}

\paragraph{Dataset}
\label{par:dataset}
In all three experiments, we leverage data from the Individual Brain Charting dataset \citep{ibc}.
It is a longitudinal study on 12 human subjects,
comprising 400 fMRI maps per subject collected
on a wide variety of stimuli (motor, visual, auditory, theory of mind,
language, mathematics, emotions, and more), movie-watching data, T1-weighted maps, as well as other features such as
retinotopy which we don't use in this work. We leverage these 400 fMRI maps.
The training, validation and test sets respectively comprise
326, 43 and 30 contrast maps acquired for each individual of the dataset.
Tasks and MRI sessions differ between each of the sets.
% More details, including preprocessing, are provided in Supplementary Materials.

\paragraph{Baseline alignment correlation}
For each pair of individuals $(s, t)$ under study, and for each fMRI contrast $c$ in the test set,
we compute the Pearson correlation $\text{corr}(F^s_{\cdot, c}, F^t_{\cdot, c})$
after these maps have been projected onto a common surface anatomy (in this case, \emph{fsaverage5}
mesh). Throughout this work, such computations are made for each hemisphere separately.

\paragraph{Experiment 1 - Aligning pairs of humans with the same anatomy}
%
For each pair $(s, t)$ under study, we derive an alignment $P^{s,t} \in \bbR^{n \times p}$
using FUGW on a set of training features. In this experiment, source and target data
lie on the same anatomical mesh (\emph{fsaverage5}), and $n = p = 10240$ for each hemisphere.
Since each hemisphere's mesh is connected, we align one hemisphere at a time.

Computed couplings are used to align contrast maps of a the validation set from
the source subject onto the target subject. Indeed, one can define
$\phi_{s \rightarrow t} \colon X \in \bbR^{n \times q}
\mapsto \big((P^{s,t})^T X \big) \oslash P^{s,t}_{\#2} \in \bbR^{p \times q}$
where $\oslash$ represents the element-wise division. $\phi_{s \rightarrow t}$
transports any matrix of features from the source mesh to the target mesh.
We measure the Pearson correlation $\text{corr}\big( \phi_{s \rightarrow t}(F^s), F^t \big)$
between each aligned source and target maps.

We run a similar experiment for MSM and compute the correlation gain induced on a
test set by FUGW and MSM respectively.
For both models, we selected the hyper-parameters maximizing correlation gain on a validation set.
In the case of FUGW, in addition to gains in correlation, hyper-parameter selection
was influenced by three other metrics that help us assess the relevance of computed couplings:

\begin{description}
    \item[Transported mass]
    For each vertex $i$ of the source subject, we compute
    $\sum \limits_{0 \leq j < p} P^{s,t}_{i, j}$.

    \item[Vertex displacement]
    Taking advantage of the fact that the source and target anatomies are the same,
    we define $D = D^s = D^t$ and compute for each vertex $i$ of the source subject the quantity
    $\sum_j P^{s,t}_{i, j} \cdot D_{i, j} / \sum_j P^{s,t}_{i,j}$,
    which measures the average geodesic distance on the cortical sheet between vertex $i$
    and the vertices of the target it has been matched with.

    \item[Vertex spread]
    Large values of $\varepsilon$ increase the entropy of derived couplings.
    To quantify this effect, and because we don't want the matching to be too blurry,
    we assess how much a vertex was \textit{spread}. Considering
    $\tilde{P_i} = P^{s,t}_i / \sum_j P^{s,t}_{i,j} \in \bbR^p$
    as a probability measure on target vertices,
    we estimate the anatomical variance of this measure by sampling $q$ pairs
    $(j_q, k_q)$ of $\tilde{P_i}$ and computing their average geodesic distance
    $\frac{1}{q} \sum\limits_{j_q, k_q} D_{j_q, k_q}$.
\end{description}

\paragraph{Experiment 2 - Aligning pairs of humans with individual anatomies}
We perform a second alignment experiment, this time using individual meshes instead of
an anatomical template. Importantly, in this case,  there is no possibility to compare
FUGW with baseline methods, since those cannot handle this case.
However, individual meshes are significantly larger than the
common anatomical template used in Experiment 1 ($n \approx m \approx$ 160k vs. 10k previously),
resulting in couplings too large to fit on GPUs -- for reference,
a coupling of size 10k $\times$ 10k already weights ~400Mo on disk.
We thus reduce the size of the source and target data by
clustering them into 10k small connected clusters using Ward's algorithm \citep{thirion:2014}.
% More details are given in supplementary section A.4.

\paragraph{Experiment 3 - Comparing FUGW barycenters with usual group analysis}
\label{par:barycenter}

Since it is very difficult to estimate the barycentric mesh, we force it to be equal to
the \emph{fsaverage5} template. Empirically, this we force the distance matrix $D^B$
to be equal to that of \emph{fsaverage5}, and only estimate the functional barycenter $F^B$.
We initialize it with the mean of $(F^s)_{s \in S}$
and derive $F^B$ and $(P^{s,B})_{s \in S}$ from Problem \eqref{eq:barycenter}.
Then, for a given stimulus $c$, we compute its projection onto the barycenter for each subject.
We use these projections to compute two maps of interest:
\textit{(i)} $M_{B,c}$ the mean of projected contrast maps across subjects
and \textit{(ii)} $T_{B,c}$ the t-statistic (for each vertex) of projected maps.
We compare these two maps with their unaligned counterparts $M_{0,c}$ and $T_{0,c}$ respectively.
\begin{figure}[ht]
    \begin{minipage}{.4\linewidth}
        \begin{equation*}
            M_{B,c} \triangleq \frac{1}{|S|} \sum_{s \in S} \phi_{s \rightarrow t}(F^s_{\cdot, c})
        \end{equation*}
    \end{minipage}
    \hfil
    \begin{minipage}{.5\linewidth}
        \begin{equation*}
            T_{B,c} \triangleq \text{t-statistic} \Big( \big(
                \phi_{s \rightarrow t}(F^s_{\cdot, c}) \big)_{s \in S} \Big)
        \end{equation*}
    \end{minipage}
\end{figure}
% \vspace*{-0.5\baselineskip}
\begin{figure}[ht]
    \begin{minipage}{.4\linewidth}
        \begin{equation*}
            M_{0,c} \triangleq \frac{1}{|S|} \sum_{s \in S} F^s_{\cdot, c}
        \end{equation*}
    \end{minipage}
    \hfil
    \begin{minipage}{.5\linewidth}
        \begin{equation*}
            T_{0,c} \triangleq \text{t-statistic} \Big( (F^s_{\cdot, c})_{s \in S} \Big)
        \end{equation*}
    \end{minipage}
\end{figure}
The first map helps us to qualitatively evaluate the precision of FUGW alignments and barycenter.
The second one is classically used to infer the existence of areas of the brain that
respond to specific stimuli. We assess whether FUGW helps find the same clusters of vertices.
Eventually, we quantify the number of vertices significantly activated or deactivated
with and without alignment respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 1 - Template anatomy}

\paragraph{Aligning subjects on a fixed mesh}

We set $\alpha = 0.5$, $\rho = 1$ and $\varepsilon = 10^{-3}$.
Pearson correlation between source and target contrast maps is systematically and
significantly increased when aligned using FUGW, as illustrated in
\Cref{fig:gain_comparisions_fsaverage5} where correlation grows by almost $40\%$
from $0.258$ to $0.356$.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.49\columnwidth]{./Chapitre4/figures/fsaverage5_alignment_correlation_gain_msm.pdf}
    \includegraphics[width=0.49\columnwidth]{./Chapitre4/figures/fsaverage5_alignment_correlation_gain_fugw.pdf}
    \caption[Comparison of gains in correlation after inter-subject alignment]{
        \textbf{Comparison of gains in correlation after inter-subject alignment}
        For each pair of source and target subjects of the dataset,
        we compute the average Pearson correlation between 30 test contrasts,
        leading to the (baseline) correspondence score,
        and compare it with that of the same contrast maps
        aligned with either MSM (left) or FUGW (right). Correlation gains are much better for FUGW.
    }
    \label{fig:gain_comparisions_fsaverage5}
\end{figure}
% We also varied training sets by selecting subsets of training contrasts and find that
% similar performance on the test set can be achieved regardless of the training data
% (see Supplementary \Cref{sec:control_experiments} and in particular Supplementary
% \Cref{tab:varying_training_sets}).

\paragraph{Hyper-parameters selection}
\label{par:params_selection}

Hyper-parameters used to obtain these results were chosen
after running a grid search on $\alpha$, $\varepsilon$ and $\rho$
and evaluating it on the validation dataset.
Computation took about 100 hours using 4 Tesla V100-DGXS-32GB GPUs. More precisely,
it takes about 4 minutes to compute one coupling between a source and target 10k-vertex
hemisphere on a single GPU, when the solver was set to run 10 BCD and 400 Sinkhorn iterations.
In comparison, MSM takes about the same time on Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz CPUs.
Results are reported in \Cref{fig:cv_metrics} and provide multiple insights concerning FUGW.

Firstly, without anatomical constraint ($\alpha = 0$),
source vertices can be matched with target vertices
that are arbitrarily far on the cortical sheet.
Even though this can significantly increase correlation, it also
results in very high vertex displacement values (up to $100mm$).
Such couplings are not anatomically plausible.
%
Secondly, without functional information ($\alpha = 1$),
couplings recover a nearly flawless matching between source and target meshes,
so that, when $\varepsilon = 10^{-5}$
(ie when we force couplings to find single-vertex-to-single-vertex matches),
vertex displacement and spread are close to 0 and correlation is unchanged.
%
Fusing both constraints ($0 < \alpha < 1$)
yields the largest gains in correlation while allowing to compute
anatomically plausible reorganizations the cortical sheet between subjects.

The impact of $\rho$ (controlling marginal penalizations) on correlation seems modest,
with a slight tendency of increased correlation in unbalanced problems (low $\rho$).

Finally, it is worth noting that a relatively wide range of $\alpha$ and $\rho$ yield comparable gains.
The fact that FUGW performance is weakly sensitive to hyper-parameters makes it
a good off-the-shelf tool for neuroscientists who wish to derive inter-individual alignments.
However, $\varepsilon$ is of dramatic importance in computed results and should be chosen carefully.
Vertex spread is a useful metric to choose sensible values of $\varepsilon$;
for human data one might consider that it should not exceed $20mm$.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\columnwidth]{./Chapitre4/figures/cv_all_metrics_hcp_left_fugw.pdf}
    \caption[Exploring hyper-parameter space to find relevant couplings]{
        \textbf{Exploring hyper-parameter space to find relevant couplings}
        Given a transport plan aligning a source and target subject,
        we evaluate how much this coupling
        (left) improves correlation between unseen contrast maps
        of the two subjects,
        (center left) actually transports data,
        (center right) moves vertices far from their original location on the cortical surface
        and (right) spreads vertices on the cortical sheet.
        We seek plans that maximize correlation gain, while keeping spread and displacement low enough.
    }
    \label{fig:cv_metrics}
\end{figure}

\paragraph{Mass redistribution in unbalanced couplings}
Unbalanced couplings provide additional information about how functional areas might differ
in size between pairs of individuals. This is illustrated in \Cref{fig:transported_mass},
where we observe variation in size of the auditory area between a given pair of individuals.
This feature is indeed captured by the difference of mass between subjects
(although the displayed contrast was not part of the training set).
\begin{figure}[!th]
    \centering
    \includegraphics[width=1\columnwidth]{./Chapitre4/figures/transported_mass.pdf}
    \caption[Transported mass indicates areas which have to be resized between subjects]{
        \textbf{Transported mass indicates areas which have to be resized between subjects}
        (Panel A) We show a contrast map from the test set which displays areas showing
        stronger activation during auditory tasks versus equivalent visual tasks. It shows much more
        anterior activations on the target subject compared to the source subject.
        This is consistent with the observation that more mass is present in
        anterior auditory areas of the source subject than in the target subject (Panel B).
    }
    \label{fig:transported_mass}
\end{figure}

\subsection{Experiment 2 - Individual anatomies}
\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\columnwidth]{./Chapitre4/figures/individual_alignment_correlation_gain_fugw}
    \caption[Correlation between pairs of subjects is significantly better after alignment on individual anatomies than after projecting subjects onto a common anatomical template]{
        \textbf{Correlation between pairs of subjects is significantly better after alignment on individual anatomies than after projecting subjects onto a common anatomical template}
    }
    \label{fig:gain_comparisions_individual}
\end{figure}

As shown in \Cref{fig:gain_comparisions_individual},
we obtain correlation gains which are comparable to that of Experiment 1 (about 35\% gain)
while working on individual meshes.
This tends to show that FUGW can compute meaningful alignments between pairs of individuals
without the use of an anatomical template, which helps bridge most conceptual impediments listed
in \Cref{sec:introduction}.
Moreover, this opens the way for computation of simple statistics in cohorts of individuals
in the absence of a template. Indeed, one can pick an individual of the cohort and use it
as a reference subject on which to transport all other individuals.
We give an example in \Cref{fig:individual_projections},
showing that FUGW correctly preserved idiosyncrasies of each subject while
transporting their functional signal in an anatomically sound way.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\columnwidth]{./Chapitre4/figures/individual_alignment.pdf}
    \caption[Transporting individual maps onto a reference subject]{
        \textbf{Transporting individual maps onto a reference subject}
        FUGW can help bridge the absence of template anatomies
        and derive pairs of alignments such that all individuals
        of the cohort are comparable. We display a map taken from the test set contrasting areas activated during mathematical reasoning against areas activated for other stimuli of the protocol.
    }
    \label{fig:individual_projections}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment 3 - Barycenter}

In the absence of a proper metric to quantify the correctness of a barycenter,
we first qualitatively compare the functional templates obtained with and without alignment.
In \Cref{fig:barycenter_vs_group_average}.A, we do so using brain maps taken from the test set.
We can see that the barycenter obtained with FUGW yields sharper contrasts and
more fine-grained details than the barycenter obtained by per-vertex averaging.
We also display in \Cref{fig:barycenter_vs_group_average}.B
the result of a one-sample test for the same contrast, which can readily be used for inference.
The one-sample test map obtained after alignment to the FUGW template exhibits
the same supra-threshold clusters as the original approach, but also some additional spots
which were likely lost due to inter-subject variability in the \emph{fsaverage5} space.
This approach is thus very useful to increase power in group inference.
We quantify this result by counting the number of supra-threshold vertices
with and without alignment for each contrast map of the test set.
Our alignment method significantly finds more such vertices of interest,
as shown in \Cref{fig:barycenter_vs_group_average}.C.
\begin{figure}[t]
    \centering
    \includegraphics[width=1\columnwidth]{./Chapitre4/figures/barycenter_group_analysis.pdf}
    \caption[FUGW barycenter yields much finer-grained maps than group averages]{
        \textbf{FUGW barycenter yields much finer-grained maps than group averages}
        We study the same statistical map as in \Cref{fig:intro}, which contrasts
        areas of the brain involved in mathematical reasoning.
        \textbf{A}. These complex maps projected onto the barycenter and averaged
        show more specific activation patterns than simple group averages,
        especially in cortical areas exhibiting more variability, such as the prefrontal cortex.
        \textbf{B}. Deriving a t-test on aligned maps captures the same clusters
        as the classical approach (plain green circles), but also new clusters in areas
        where inter-subject variability is high (dotted black circles).
        Peak t-statistics are also higher with FUGW.
        \textbf{C}. Ratio of number of activated vertices ($|\text{t-statistic}| \geq 4$)
        with versus without alignment for each map of the test set.
        Our method finds significantly more of such vertices ($\text{p-value} = 3\cdot10^{-4}$).}
    \label{fig:barycenter_vs_group_average}
\end{figure}

\section{Discussion}

FUGW can derive meaningful couplings between pairs of subjects without
the need of a pre-existing anatomical template. It is well-suited to computing
barycenters of individuals, even for small cohorts.

In addition, we have shown clear evidence that FUGW yields gains that cannot be achieved
by traditional diffeomorphic registration methods.
These methods impose very strong constraints to the displacement field,
that may prevent reaching optimal configurations.
More deeply, this finding suggests that brain comparison ultimately requires
lifting hard regularity constraints on the alignment models,
and that two human brains differ by more than a simple continuous surface deformation.
However, current results have not shown a strong correlation gain of
unbalanced OT compared to balanced OT, likely because the cohort under study is too small.
Leveraging datasets such as HCP \citep{hcpdata} with a larger number of subjects
will help lower the standard error on correlation gain estimates.
In this work, we decided to rely on a predefined anatomical template (\emph{fsaverage5})
to derive functional barycenters.
It would be interesting to investigate whether more representative anatomical templates
can be learned during the process.
This would in particular help to customize templates to different populations or species.

Additionally, using an entropic solver introduces a new hyper-parameter $\varepsilon$
that has a strong effect, but is hard to interpret.
Future work may replace the Sinkhorn algorithm \citep{Sejourne19}
used here by the majorization-minimization one \citep{Chapel20},
which does not require entropic smoothing. This solution can yield sparse couplings
while being orders of magnitude faster, which will prove useful when computing barycenters
on large cohorts.

Finally, we plan to make use of FUGW to derive alignments between human and
non-human primates without anatomical priors. Indeed, the understanding of given brain mechanisms
will benefit from more detailed invasive measurements made on other species \emph{only if}
brains can be matched across species; moreover, this  raises the question of features
that make the human brain unique, by identifying patterns that have no counterpart in other species.
By maximizing the functional alignment between areas, but also allowing for some regions
to be massively shrunk or downright absent in one species relative to the other,
the present tool could shed an objective light on the important issue of whether
and how the language-related areas of the human cortical sheet map onto
the architecture of non-human primate brains.

\vfill