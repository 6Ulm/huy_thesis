\section{Appendix of Chapter 2}

\subsection{Proofs related to Unbalanced Optimal Transport}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{proof}[Proof of \Cref{coro:uot_l2_mm}]
Following \citep{Chapel21}, we can write Problem \eqref{uot_l2} as
\begin{align}
    \min_{t \in \bbR^{mn}_{\geq 0}} \langle c, t \rangle + \frac{|| Mt - y ||^2}{2},
\end{align}
where $t = \vect(P), c = \vect(C)$ are the vectorizations of $P, C$, respectively. Here,
\begin{itemize}
    \item[$\bullet$] $M = (\rho_1^{1/2} M_r^T, \rho_2^{1/2} M_c^T, \varepsilon^{1/2} I_{mn})^T \in \bbR^{(m + n + mn) \times (mn)}$.

    \item[$\bullet$] $y = (\rho_1^{1/2} \mu^T, \rho_2^{1/2} \nu^T, \varepsilon^{1/2} \vect(\gamma)^T)^T \in \bbR^{m + n + mn}$.

    \item[$\bullet$] $M_r = \texttt{np.repeat(np.eye(n),m)} \in \bbR^{n \times mn}$.

    \item[$\bullet$] $M_c = [I_m, ..., I_m] = \texttt{np.tile(np.eye(m),n)} \in \bbR^{m \times mn}$.
\end{itemize}
See Appendix A in \citep{Chapel21} for more details of $M_r, M_c$.
Remark that if $A \in \bbR^{m \times n}$ and $B \in \bbR^{m \times p}$, then
\begin{align}
    (A, B) \begin{pmatrix}
        X^T \\
        B^T
    \end{pmatrix}
    = X X^T + B B^T.
\end{align}
Following Equation 23 in \citep{Chapel21},  we have
\begin{align}
    t^{(k+1)}_i = t^{(k)}_i \frac{\max( 0, [M^T y]_i - c_i)}{[M^T M t^{(k)}]_i}.
\end{align}
Now, $\text{mat}(M^T y) = (\rho_1 \mu) \oplus (\rho_2 \nu) + \varepsilon \gamma$.
Here, matrization is the inverse operation of vectorization. Since,
$M^T M = \rho_1 M_r^T M_r + \rho_2 M_c^T M_c + \varepsilon I_{mn}$, we obtain
$\text{mat}(M^T M t^{(k)}) = (\rho_1 P_{\# 1}^{(k)}) \oplus (\rho_2 P_{\# 2}^{(k)})
+ \varepsilon P^{(k)} $. The result then follows.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{proof}[Proof of \Cref{prop:uot_minimizer}]
We follow the same proof technique of Lemma 4 in \citep{Khiem20}.
Given a Bregman divergence $D_{\psi}$, for any $t \in \bbR$ such that $tp \in \text{dom}(\psi)$,
we have
\begin{align}
  D_{\psi}(t p | q)
  &= \psi(tp) - \psi(q) - \langle \nabla \psi(q), tp - q \rangle \\
  &= \psi(tp) - \psi(q) - \Big[
    t \langle \nabla \psi(q), p - q \rangle + (t-1) \langle \nabla \psi(q), q \rangle
  \Big] \\
  &= \psi(tp) - \psi(q) + t \Big[ D_{\psi}(p | q) + \psi(q) - \psi(p) \Big]
  - (t-1) \langle \nabla \psi(q), q \rangle \\
  &= t D_{\psi}(p | q) + \big[ \psi(tp) - t \psi(p) \big]
  + (t-1) \big[ \psi(q) - \langle \nabla \psi(q), q \rangle \big].
\end{align}
Denote $g$ the objective function of Problem \eqref{eq:uot_bregman}. We have,
\begin{align}
  g(tP) &= t g(P) +
  \underbrace{\Big( \sum_{k=1}^2 \rho_k \big[ \varphi_k(tP_{\# k}) - t \varphi_k(P_{\# k}) \big]
  + \varepsilon \big[ \varphi(tP) - t \varphi(P) \big] \Big)}_{A(t)} \\
  &+ (t-1) \underbrace{\Big(
    \sum_{k=1}^2 \rho_k \big[ \varphi_k(\mu_k) - \langle \nabla \varphi_k(\mu_k), \mu_k \rangle \big]
    + \varepsilon \big[ \varphi(\gamma) - \langle \nabla \varphi(\gamma), \gamma \rangle \big]
    \Big)}_{B} \\
    &= t g(P) + A(t) + (t-1) B.
\end{align}
For any minimizer $P^* \in \cC$, denote $\cT^* =\{ t \in \bbR: tP^* \in \cC \}$. Clearly, $\cT^*$ is
not empty since $1 \in \cT^*$. Since $P^*$ is a (global) minimizer, we have
$\frac{\partial g(tP^*)}{\partial t} \Big |_{t = 1} = 0$,
or equivalently,
\begin{align}
  g(P^*) &= - B - \frac{\partial A(t)}{\partial t} \bigg|_{t=1} \\
  &= \sum_{k=1}^2 \rho_k \Big[ \langle \nabla \varphi_k(\mu_k), \mu_k \rangle - \varphi_k(\mu_k) \Big]
  + \varepsilon \Big[ \langle \nabla \varphi(\gamma), \gamma \rangle - \varphi(\gamma) \Big] \\
  &+ \sum_{k=1}^2
  \rho_k \Bigg( \varphi_k(P^*_{\# k}) - \frac{\partial \varphi_k(tP^*_{\# k})}{\partial t} \bigg|_{t=1} \Bigg)
  + \varepsilon \Bigg( \varphi(P^*) - \frac{\partial \varphi(tP^*)}{\partial t} \bigg|_{t=1} \Bigg).
\end{align}
The result then follows.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proofs related to Gromov-Wasserstein distance} \label{subsec:appendix_gw}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{corollary}
    The formulations \eqref{GH:zeroth} and \eqref{GH:first} of the Gromov-Hausdorff distance
    are equivalent.
\end{corollary}
\begin{proof}
In the formulation \eqref{GH:first}, by choosing identity mappings (which are clearly isometric embeddings)
$f = \id_X$ and $g = \id_Y$, and $Z = X \cup Y$ equipped with an admissible distance $d$, we have
\begin{equation}
  \gh((X,d_X), (Y,d_Y)) \leq d_{H}^{(Z,d)}(X, Y)
\end{equation}
As this is true for any $d \in \cD(d_X,d_Y)$, we have
$\gh((X,d_X), (Y,d_Y)) \leq \inf_{d} d_{H}^{(X \cup Y, d)}(X, Y)$. For the reverse direction,
given any isometries $f: X \to X'$ and $g: Y \to Y'$ with $X', Y' \subset (Z, d_Z)$
(we call $(X',Y')$ a \textit{metric coupling} \citep{Villani08}), one can define
a distance $d$ on $X \cup Y$ (as shown in Proposition 27.1 in \citep{Villani08}). Then,
\begin{equation}
  \begin{split}
    d_H^{(Z, d_Z)}(f(X), g(Y)) &=
  \max(\sup_{y \in Y} d_Z(g(y), f(X)), \sup_{x \in X} d_Z(f(x), g(Y))) \\
  &= \max(\sup_{y \in Y} d(y, X), \sup_{x \in X} d(x, Y)) \\
  &= d_H^{(X \cup Y, d)}(X, Y) \geq \inf_{d'} d_{H}^{(X \cup Y, d')}(X, Y)
  \end{split}
\end{equation}
We deduce that $\gh((X,d_X), (Y,d_Y)) \geq \inf_{d} d_{H}^{(X \cup Y, d)}(X, Y)$,
thus equality holds.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{proof}[Proof of \Cref{lemma:fgw_pgd}]
  Denote $F(P) = \langle C \otimes P, P \rangle + \langle M, P \rangle + \varepsilon \kl(P | \gamma)$.
  Then $\nabla F(P) = C \otimes P + M + \varepsilon \log \frac{P}{\gamma}$.
  The PGD iterate reads: for $\tau > 0$,
  \begin{align}
    P^{(t+1)} = \text{proj}^{\kl}_{U(\mu_x, \mu_y)}
    \left( P^{(t)} \odot e^{-\tau \nabla F(P^{(t)})} \right),
  \end{align}
  where $\text{proj}^{\kl}_{U(\mu_x, \mu_y)}(K) =
  \argmin_{P \in U(\mu_x, \mu_y)} - \varepsilon \langle \log K, P \rangle + \varepsilon H(P)$.
  Denote $\eta = \tau \varepsilon$. We have
  \begin{align}
    \log K &= \log \left( P^{(t)} \odot e^{-\tau \nabla F(P^{(t)})} \right) \\
    &= \log P^{(t)} - \tau (C \otimes P^{(t)} + M)  - \tau \varepsilon \log \frac{P^{(t)}}{\gamma} \\
    &= - \tau (C \otimes P^{(t)} + M) + \log \left( \gamma^{\eta} \odot (P^{(t)})^{1 - \eta} \right).
  \end{align}
  We deduce that
  \begin{align}
    &- \varepsilon \langle \log K, P \rangle + \varepsilon H(P) \\
    &= \eta \langle C \otimes P^{(t)} + M, P \rangle
    - \varepsilon \langle P, \log \left( \gamma^{\eta} \odot (P^{(t)})^{1 - \eta} \right) \rangle
    + \varepsilon H(P) \\
    &= \eta \langle C \otimes P^{(t)} + M, P \rangle +
    \varepsilon \kl \left( P \big | \gamma^{\eta} \odot (P^{(t)})^{1 - \eta} \right)
    - m \left( \gamma^{\eta} \odot (P^{(t)})^{1 - \eta} \right),
  \end{align}
  where $m(Q) = \sum_{i,j} Q_{ij}$ is the mass of measure $Q$. The result then follows.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%